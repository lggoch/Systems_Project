{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = []\n",
    "values= []\n",
    "with open(\"rcv1rcv2aminigoutte/EN/Index_EN-EN\") as rcv1:\n",
    "    for line in rcv1.readlines():\n",
    "        line = line.strip()\n",
    "        index.append(line.split(' ')[0])\n",
    "        values.append(line.split(' ')[1:])\n",
    "        \n",
    "\n",
    "matrix = np.zeros((len(index),21531))\n",
    "\n",
    "for i, row in enumerate(values):\n",
    "    for val in row:\n",
    "        tup = val.split(':')\n",
    "        col = int(tup[0])-1\n",
    "        matrix[i][col] = float(tup[1])\n",
    "\n",
    "features = np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    centered_data = np.subtract(x, np.nanmean(x, axis=0))\n",
    "    std_data = centered_data / np.nanstd(centered_data, axis=0)\n",
    "    std_data = np.nan_to_num(std_data)\n",
    "    return std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = standardize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge_loss(y, X, w):\n",
    "    loss = np.zeros(y.shape)\n",
    "    f = X@w\n",
    "    ## Penalize but indicative for the prints\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1 and f[i] < 1:\n",
    "            loss[i] = (1-y[i]*f[i])*9\n",
    "        else:\n",
    "            loss[i] = 1-y[i]*f[i]\n",
    "    #print(np.clip(loss,0, np.inf))\n",
    "    return np.clip(loss,0, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(y,X,w, lambda_, n, num_examples):\n",
    "    def is_support(y_n, x_n, w):\n",
    "        return y_n * x_n @w < 1\n",
    "    x_n, y_n = X[n], y[n]\n",
    "    ## Penalize the gradient\n",
    "    if y_n == 1 and x_n@w <1:\n",
    "        grad = - 8*y_n * x_n.T if is_support(y_n, x_n, w) else np.zeros_like(x_n.T)\n",
    "    else:\n",
    "        grad = - y_n * x_n.T if is_support(y_n, x_n, w) else np.zeros_like(x_n.T)\n",
    "    grad = num_examples * np.squeeze(grad) + lambda_ * w\n",
    "    return grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_primal(y, X, w, lambda_):\n",
    "    v = hinge_loss(y, X, w)\n",
    "    return np.sum(v) + lambda_ / 2 * np.sum(w**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_for_svm(y,X):\n",
    "    max_iter = 500000\n",
    "    gamma = 0.3\n",
    "    lambda_ = 0.01\n",
    "    num_examples, num_features = features.shape\n",
    "    w = np.zeros(num_features)\n",
    "    for it in range(max_iter):\n",
    "        n = random.randint(0, num_examples-1)\n",
    "        grad = SGD(y, X, w, lambda_, n, num_examples)\n",
    "        w-= gamma*grad\n",
    "        \n",
    "        if it % 10000 == 0:\n",
    "            cost = calculate_primal(y, X, w, lambda_)\n",
    "            print(\"iteration={i}, cost={c}\".format(i=it, c=cost))\n",
    "    print(\"training accuracy = {l}\".format(l=calculate_accuracy(y, X, w)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(index, category):\n",
    "    def convert_to_bin(cat):\n",
    "        return 1 if cat == category else -1\n",
    "    labels = map(convert_to_bin, index)\n",
    "    return np.array(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y1, y2):\n",
    "    return np.mean(y1 == y2)\n",
    "\n",
    "def prediction(X, w):\n",
    "    return (X @ w > 0) * 2 - 1\n",
    "def calculate_accuracy(y, X, w):\n",
    "    \"\"\"compute the training accuracy on the training set (can be called for test set as well).\n",
    "    X: the full dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_features)\n",
    "    \"\"\"\n",
    "    predicted_y = prediction(X, w)\n",
    "    return accuracy(predicted_y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=0, cost=10571299882.448761\n",
      "iteration=10000, cost=1752540602381.3203\n",
      "iteration=20000, cost=852422574472.197\n",
      "iteration=30000, cost=1060010910779.144\n",
      "iteration=40000, cost=797671423073.464\n",
      "iteration=50000, cost=997120159202.276\n",
      "iteration=60000, cost=706664855971.6936\n",
      "iteration=70000, cost=618987768120.8668\n",
      "iteration=80000, cost=1359550614415.2273\n",
      "iteration=90000, cost=1623364232411.3813\n",
      "iteration=100000, cost=1455578079443.3987\n",
      "iteration=110000, cost=1128302078851.5474\n",
      "iteration=120000, cost=1308672337701.6719\n",
      "iteration=130000, cost=983776515718.244\n",
      "iteration=140000, cost=1491900643247.9048\n",
      "iteration=150000, cost=1278623565007.5015\n",
      "iteration=160000, cost=879577748201.2035\n",
      "iteration=170000, cost=1380504137181.4575\n",
      "iteration=180000, cost=1393569653995.48\n",
      "iteration=190000, cost=777805729241.6956\n",
      "iteration=200000, cost=1405240023366.2993\n",
      "iteration=210000, cost=1328670182925.471\n",
      "iteration=220000, cost=1048743047321.5085\n",
      "iteration=230000, cost=1695170163497.0564\n",
      "iteration=240000, cost=1563897729159.3628\n",
      "iteration=250000, cost=1311274446491.026\n",
      "iteration=260000, cost=866843977964.8306\n",
      "iteration=270000, cost=925391371217.248\n",
      "iteration=280000, cost=1037335074638.7913\n",
      "iteration=290000, cost=996864275615.9613\n",
      "iteration=300000, cost=1055506027298.8538\n",
      "iteration=310000, cost=843586963454.1033\n",
      "iteration=320000, cost=1466912867501.2126\n",
      "iteration=330000, cost=1848404307384.8662\n",
      "iteration=340000, cost=1274766732348.613\n",
      "iteration=350000, cost=1905988395445.4204\n",
      "iteration=360000, cost=1524875519124.0164\n",
      "iteration=370000, cost=1654447826544.9617\n",
      "iteration=380000, cost=1186362992171.4983\n",
      "iteration=390000, cost=736017565679.8181\n",
      "iteration=400000, cost=1485683418065.0215\n",
      "iteration=410000, cost=1544751698345.0059\n",
      "iteration=420000, cost=1798014347581.9375\n",
      "iteration=430000, cost=934996862384.0364\n",
      "iteration=440000, cost=1981308072743.8206\n",
      "iteration=450000, cost=870605323304.2706\n",
      "iteration=460000, cost=1473890388014.4192\n",
      "iteration=470000, cost=1372668878660.868\n",
      "iteration=480000, cost=1100966730840.9966\n",
      "iteration=490000, cost=760403964931.525\n",
      "training accuracy = 0.6893592067384583\n"
     ]
    }
   ],
   "source": [
    "sgd_for_svm(create_labels(index, \"ECAT\"), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_coordinate_update(y, X, lambda_, alpha, w, n):\n",
    "    \"\"\"compute a coordinate update (closed form) for coordinate n.\n",
    "    X: the dataset matrix, shape = (num_examples, num_features)\n",
    "    y: the corresponding +1 or -1 labels, shape = (num_examples)\n",
    "    w: shape = (num_examples)\n",
    "    n: the coordinate to be updated\n",
    "    \"\"\"        \n",
    "    # calculate the update of coordinate at index=n.\n",
    "    x_n, y_n = X[n], y[n]\n",
    "    old_alpha_n = np.copy(alpha[n])\n",
    "    \n",
    "    ## Penalize coordinate update\n",
    "    if y_n == 1 and x_n.dot(w) < 1:\n",
    "        g = (y_n * x_n.dot(w) - 1)*8\n",
    "    else:\n",
    "        g = (y_n * x_n.dot(w) - 1)\n",
    "    \n",
    "\n",
    "    if old_alpha_n == 0:\n",
    "        g = min(g, 0)\n",
    "    elif old_alpha_n == 1.0:\n",
    "        g = max(g, 0)\n",
    "    else:\n",
    "        g = g\n",
    "    if g != 0:\n",
    "        alpha[n] = min(\n",
    "            max(old_alpha_n - lambda_ * g / (x_n.T.dot(x_n)), 0.0),\n",
    "            1.0)\n",
    "    \n",
    "        # compute the corresponding update on the primal vector w\n",
    "        w += 1.0 / lambda_ * (alpha[n] - old_alpha_n) * y_n * x_n\n",
    "    return w, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_dual_objective(y, X, w, alpha, lambda_):\n",
    "    \"\"\"calculate the objective for the dual problem.\"\"\"\n",
    "    return np.sum(alpha)  - lambda_ / 2.0 * np.sum(w ** 2) # w = 1/lambda * X * Y * alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=0, primal:35203.40957, dual:0.00000, gap:35203.40957\n",
      "iteration=10000, primal:15074.65233, dual:-0.00060, gap:15074.65294\n",
      "iteration=20000, primal:13720.24460, dual:0.00170, gap:13720.24290\n",
      "iteration=30000, primal:12201.08163, dual:0.00429, gap:12201.07734\n",
      "iteration=40000, primal:11560.19332, dual:0.00641, gap:11560.18691\n",
      "iteration=50000, primal:10520.88281, dual:0.00812, gap:10520.87469\n",
      "iteration=60000, primal:9482.74840, dual:0.00982, gap:9482.73858\n",
      "iteration=70000, primal:8741.84638, dual:0.01176, gap:8741.83462\n",
      "iteration=80000, primal:7839.85733, dual:0.01296, gap:7839.84437\n",
      "iteration=90000, primal:7514.18890, dual:0.01430, gap:7514.17460\n",
      "iteration=100000, primal:6915.74568, dual:0.01533, gap:6915.73035\n",
      "iteration=110000, primal:6446.46714, dual:0.01634, gap:6446.45080\n",
      "iteration=120000, primal:6146.14696, dual:0.01720, gap:6146.12976\n",
      "iteration=130000, primal:5659.81303, dual:0.01793, gap:5659.79510\n",
      "iteration=140000, primal:5295.10450, dual:0.01853, gap:5295.08597\n",
      "iteration=150000, primal:5162.57744, dual:0.01910, gap:5162.55835\n",
      "iteration=160000, primal:4891.06053, dual:0.01964, gap:4891.04089\n",
      "iteration=170000, primal:4447.53817, dual:0.02007, gap:4447.51810\n",
      "iteration=180000, primal:4396.05246, dual:0.02048, gap:4396.03198\n",
      "iteration=190000, primal:4099.80093, dual:0.02084, gap:4099.78009\n",
      "iteration=200000, primal:3852.97750, dual:0.02117, gap:3852.95634\n",
      "iteration=210000, primal:3653.57709, dual:0.02149, gap:3653.55560\n",
      "iteration=220000, primal:3449.04022, dual:0.02177, gap:3449.01845\n",
      "iteration=230000, primal:3398.09265, dual:0.02196, gap:3398.07069\n",
      "iteration=240000, primal:3192.54279, dual:0.02223, gap:3192.52057\n",
      "iteration=250000, primal:2957.63833, dual:0.02246, gap:2957.61587\n",
      "iteration=260000, primal:2825.46834, dual:0.02268, gap:2825.44566\n",
      "iteration=270000, primal:2717.06734, dual:0.02286, gap:2717.04448\n",
      "iteration=280000, primal:2555.75171, dual:0.02303, gap:2555.72867\n",
      "iteration=290000, primal:2487.87061, dual:0.02314, gap:2487.84747\n",
      "iteration=300000, primal:2376.94681, dual:0.02331, gap:2376.92350\n",
      "iteration=310000, primal:2352.33794, dual:0.02330, gap:2352.31464\n",
      "iteration=320000, primal:2439.45415, dual:0.02355, gap:2439.43060\n",
      "iteration=330000, primal:2087.16879, dual:0.02363, gap:2087.14516\n",
      "iteration=340000, primal:2250.19908, dual:0.02386, gap:2250.17521\n",
      "iteration=350000, primal:2015.65670, dual:0.02393, gap:2015.63277\n",
      "iteration=360000, primal:1854.13464, dual:0.02404, gap:1854.11060\n",
      "iteration=370000, primal:1763.67353, dual:0.02415, gap:1763.64938\n",
      "iteration=380000, primal:1773.21003, dual:0.02416, gap:1773.18587\n",
      "iteration=390000, primal:1649.74837, dual:0.02418, gap:1649.72419\n",
      "iteration=400000, primal:1741.42482, dual:0.02433, gap:1741.40049\n",
      "iteration=410000, primal:1649.43051, dual:0.02441, gap:1649.40610\n",
      "iteration=420000, primal:1609.48488, dual:0.02443, gap:1609.46046\n",
      "iteration=430000, primal:1466.43251, dual:0.02453, gap:1466.40798\n",
      "iteration=440000, primal:1382.14638, dual:0.02461, gap:1382.12178\n",
      "iteration=450000, primal:1392.62821, dual:0.02466, gap:1392.60355\n",
      "iteration=460000, primal:1372.45667, dual:0.02470, gap:1372.43197\n",
      "iteration=470000, primal:1296.48010, dual:0.02475, gap:1296.45536\n",
      "iteration=480000, primal:1429.85084, dual:0.02462, gap:1429.82622\n",
      "iteration=490000, primal:1338.72288, dual:0.02467, gap:1338.69821\n",
      "training accuracy = 0.997867576500693\n"
     ]
    }
   ],
   "source": [
    "def coordinate_descent_for_svm_demo(y, X):\n",
    "    max_iter = 500000\n",
    "    lambda_ = 0.01\n",
    "\n",
    "    num_examples, num_features = X.shape\n",
    "    w = np.zeros(num_features)\n",
    "    alpha = np.zeros(num_examples)\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        # n = sample one data point uniformly at random data from x\n",
    "        n = random.randint(0,num_examples-1)\n",
    "        \n",
    "        w, alpha = calculate_coordinate_update(y, X, lambda_, alpha, w, n)\n",
    "            \n",
    "        if it % 10000 == 0:\n",
    "            # primal objective\n",
    "            primal_value = calculate_primal(y, X, w, lambda_)\n",
    "            # dual objective\n",
    "            dual_value = calculate_dual_objective(y, X, w, alpha, lambda_)\n",
    "            # primal dual gap\n",
    "            duality_gap = primal_value - dual_value\n",
    "            print('iteration=%i, primal:%.5f, dual:%.5f, gap:%.5f'%(\n",
    "                    it, primal_value, dual_value, duality_gap))\n",
    "    print(\"training accuracy = {l}\".format(l=calculate_accuracy(y, X, w)))\n",
    "\n",
    "coordinate_descent_for_svm_demo(create_labels(index, \"ECAT\"), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18292827.67315279"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "343136861493/features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAENCAYAAADpK9mHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10da1e860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "from collections import Counter\n",
    "letter_counts = Counter(index)\n",
    "df = pandas.DataFrame.from_dict(letter_counts, orient='index')\n",
    "df.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne1yRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f118320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(create_labels(index, \"ECAT\"), normed= True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
