{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import grpc\n",
    "import sgd_pb2_grpc\n",
    "import sgd_pb2\n",
    "from random import shuffle, randint\n",
    "from collections import Counter\n",
    "import operator\n",
    "import threading as th\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zeros(x):\n",
    "    '''\n",
    "    Returns a vector (in list type) consisting of x zeros\n",
    "    '''\n",
    "    return [0]*x\n",
    "\n",
    "def hinge_loss(y, X, w):\n",
    "    '''\n",
    "    Computes the Hinge loss given:\n",
    "    y: label vector\n",
    "    X: feature vector\n",
    "    w: weight vector\n",
    "    '''\n",
    "    loss = zeros(len(y))\n",
    "    f = multiply_matrix(X, w)\n",
    "    for i in range(len(y)):\n",
    "        loss[i] = max(1 - y[i] * f[i], 0)\n",
    "    return loss\n",
    "\n",
    "def multiply(x, w):\n",
    "    '''\n",
    "    Perfoms the dot product between the vector x and w\n",
    "    '''\n",
    "    y_n = 0\n",
    "    for k in x:\n",
    "        y_n += x.get(k) * w[k]\n",
    "    return y_n\n",
    "\n",
    "def multiply_matrix(X, w):\n",
    "    '''\n",
    "    Perfoms the matrix multiplication X@w\n",
    "    '''\n",
    "    y = zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        y[i] = multiply(X[i], w)\n",
    "    return y\n",
    "\n",
    "def prediction(X, w):\n",
    "    '''\n",
    "    Return the prediction labels (Â± 1) given:\n",
    "    X: feature matrix\n",
    "    w: weight vector\n",
    "    '''\n",
    "    y = multiply_matrix(X, w)\n",
    "    y = [a > 0 for a in y]\n",
    "    return [(a*2 - 1) for a in y]\n",
    "\n",
    "def accuracy(y_pred, y):\n",
    "    '''\n",
    "    Computes the accuracy given:\n",
    "    y_pred: predicted labels\n",
    "    y: test labels\n",
    "    '''\n",
    "    return sum([i == j for (i, j) in zip(y_pred, y)])/len(y)\n",
    "\n",
    "def calculate_primal(y, X, w, lambda_):\n",
    "    '''\n",
    "    Computes the primal loss with the regularizer term lambda\n",
    "    '''\n",
    "    v = hinge_loss(y, X, w)\n",
    "    return sum(v) + lambda_ / 2 * sum([w_i**2 for w_i in w])\n",
    "\n",
    "def set_labels(cat, id_, id_to_labels):\n",
    "    '''\n",
    "    Converts the article ids to a label vector for SVM given a category 'cat'\n",
    "    '''\n",
    "    labels = [1 if cat in id_to_labels[x] else -1 for x in id_]\n",
    "    return labels\n",
    "\n",
    "def split_data(tx, ty, ratio, seed=1):\n",
    "    '''\n",
    "    Splits the training data by ratio (dedicated to training)\n",
    "    '''\n",
    "    split_idxs = [i for i in range(len(tx))]\n",
    "    \n",
    "    # Shuffle the indices randomly\n",
    "    shuffle(split_idxs)\n",
    "    \n",
    "    tx_shuffled = []\n",
    "    ty_shuffled = []\n",
    "    for i in range(len(split_idxs)):\n",
    "        tx_shuffled.append(tx[split_idxs[i]])\n",
    "        ty_shuffled.append(ty[split_idxs[i]])\n",
    "    \n",
    "    # Split by ratio\n",
    "    split_pos = int(len(tx) * ratio)\n",
    "    x_train = tx_shuffled[:split_pos]\n",
    "    x_test = tx_shuffled[split_pos:]\n",
    "    y_train = ty_shuffled[:split_pos]\n",
    "    y_test = ty_shuffled[split_pos:]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def inbalance(labels):\n",
    "    '''\n",
    "    Computes the proportions of the 1s and (-1)s to balance penalizer terms\n",
    "    when calculating the loss\n",
    "    '''\n",
    "    size = len(labels)\n",
    "    c = Counter(labels)\n",
    "    corr_1 = (0.5*size)/c[-1]\n",
    "    corr_2= (0.5*size)/c[1]\n",
    "    return (corr_1, corr_2)\n",
    "\n",
    "def test(input_, q,j):\n",
    "    res = stub1.ComputeTask(input_)\n",
    "    q.put(dict(res.grad_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading of the files \n",
    "file1 = open(\"../lyrl2004_vectors_test_pt0.dat\")\n",
    "file2 = open(\"../lyrl2004_vectors_test_pt1.dat\")\n",
    "file3 = open(\"../lyrl2004_vectors_test_pt2.dat\")\n",
    "file4 = open(\"../lyrl2004_vectors_test_pt3.dat\")\n",
    "files = [file1, file2, file3, file4]\n",
    "\n",
    "# Parsing the files and storing the ids of the articles along with their respective features\n",
    "id_ = []\n",
    "samples = []\n",
    "for f in files:\n",
    "    for i in f.readlines():\n",
    "        id_.append(i.split()[0])\n",
    "        samples.append(i.strip().split()[2:])\n",
    "categories = open(\"../rcv1-v2.topics.qrels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a mapping of each article id to the set of categories it belongs to\n",
    "cat = []\n",
    "cat_count = {}\n",
    "id_to_labels = {}\n",
    "for line in open(\"../rcv1-v2.topics.qrels\").readlines():\n",
    "    s = line.split(' ')\n",
    "    id_to_labels.setdefault(s[1],[]).append(s[0])\n",
    "    cat_count.setdefault(s[0],[]).append(s[1])\n",
    "    cat.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the label vector based on the chosen category\n",
    "# Set the features matrix as sparse matrix by storing only the non zero components in a dict \n",
    "y = set_labels(\"ECAT\", id_, id_to_labels)\n",
    "X = []\n",
    "for sample in samples:\n",
    "    d = dict()\n",
    "    for feature in sample:\n",
    "        key = int(feature.split(':')[0])\n",
    "        value = float(feature.split(':')[1])\n",
    "        d[key] = value\n",
    "    X.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CCAT', 48.80891886875772),\n",
       " ('GCAT', 30.625587988710617),\n",
       " ('MCAT', 26.216456644032434),\n",
       " ('C15', 19.428106980345976),\n",
       " ('ECAT', 15.349465290266426)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a ratio count of the positive examples within each class\n",
    "count = dict(cat_count)\n",
    "sum_count = sum(list(map(lambda x: len(x),count.values())))\n",
    "for k in count:\n",
    "    count[k] = (len(count[k])/len(y))*100\n",
    "\n",
    "sorted(count.items(), key=operator.itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "x_train, y_train, x_test, y_test = split_data(X, y, ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the 'balancing' ratios (used to fairly penalize the negative vs positive examples)\n",
    "c1, c2 = inbalance(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5876636259183831 3.3518099426181154\n"
     ]
    }
   ],
   "source": [
    "print(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pick a random sample from the training set\n",
    "rd = randint(0,len(x_train))    \n",
    "batch = x_train[rd]\n",
    "lab = y_train[rd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up 2 channels for the communication\n",
    "channel1 = grpc.insecure_channel('localhost:50051')\n",
    "channel2 = grpc.insecure_channel('localhost:52251')\n",
    "stub1 = sgd_pb2_grpc.SGDStub(channel1)\n",
    "stub2 = sgd_pb2_grpc.SGDStub(channel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.907505775889103\n",
      "Test accuracy = 0.9054098161315303\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters for the SGD\n",
    "max_iter = 10000\n",
    "worker = 10\n",
    "q = queue.Queue()\n",
    "weights = zeros(47237)\n",
    "l_rate = 0.3\n",
    "lambda_ = 0.001\n",
    "\n",
    "# Performs the SVM using SGD\n",
    "for i in tqdm(range(max_iter)):\n",
    "    if(i%100 == 0):\n",
    "        print(i)\n",
    "    results = []\n",
    "    threads = []\n",
    "    for j in range(worker):\n",
    "        rd = randint(0,len(x_train))\n",
    "        batch = x_train[rd]\n",
    "        lab = y_train[rd]\n",
    "        args_ = (sgd_pb2.LWB(labels=lab, weights=weights, batch=batch, corr_1=c1, corr_2=c2, lambda_= lambda_),q,j)\n",
    "        t = th.Thread(target=test, args=args_)\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    for j in range(worker):\n",
    "        threads[j].join()\n",
    "    \n",
    "    while not q.empty():\n",
    "        results.append(q.get())\n",
    "    for update in results:\n",
    "        for x in update:\n",
    "            weights[x] -= l_rate * update[x]\n",
    "    #print(calculate_primal(labels,X,weights,0.01))\n",
    "#print(calculate_primal(y_train, x_train, weights,0.01))\n",
    "print('Training accuracy = {}'.format(accuracy(prediction(x_train, weights), y_train)))\n",
    "print('Test accuracy = {}'.format(accuracy(prediction(x_test, weights), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20310"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.Series(weights).nonzero()[0])/len(pd.Series(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = f1_score(labels,prediction(X, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = precision_score(labels,prediction(X, weights))\n",
    "r = recall_score(labels,prediction(X, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.740962516982 0.643446356275 0.873316104438\n"
     ]
    }
   ],
   "source": [
    "print(f,p,r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
