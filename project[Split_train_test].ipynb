{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import grpc\n",
    "import sgd_pb2_grpc\n",
    "import sgd_pb2\n",
    "from random import shuffle, randint\n",
    "from collections import Counter\n",
    "import operator\n",
    "import threading as th\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(x):\n",
    "    '''\n",
    "    Returns a vector (in list type) consisting of x zeros\n",
    "    '''\n",
    "    return [0]*x\n",
    "\n",
    "def hinge_loss(y, X, w):\n",
    "    '''\n",
    "    Computes the Hinge loss given:\n",
    "    y: label vector\n",
    "    X: feature vector\n",
    "    w: weight vector\n",
    "    '''\n",
    "    loss = zeros(len(y))\n",
    "    f = multiply_matrix(X, w)\n",
    "    for i in range(len(y)):\n",
    "        loss[i] = max(1 - y[i] * f[i], 0)\n",
    "    return loss\n",
    "\n",
    "def multiply(x, w):\n",
    "    '''\n",
    "    Perfoms the dot product between the vector x and w\n",
    "    '''\n",
    "    y_n = 0\n",
    "    for k in x:\n",
    "        y_n += x.get(k) * w[k]\n",
    "    return y_n\n",
    "\n",
    "def multiply_matrix(X, w):\n",
    "    '''\n",
    "    Perfoms the matrix multiplication X@w\n",
    "    '''\n",
    "    y = zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        y[i] = multiply(X[i], w)\n",
    "    return y\n",
    "\n",
    "def prediction(X, w):\n",
    "    '''\n",
    "    Return the prediction labels (Â± 1) given:\n",
    "    X: feature matrix\n",
    "    w: weight vector\n",
    "    '''\n",
    "    y = multiply_matrix(X, w)\n",
    "    y = [a > 0 for a in y]\n",
    "    return [(a*2 - 1) for a in y]\n",
    "\n",
    "def accuracy(y_pred, y):\n",
    "    '''\n",
    "    Computes the accuracy given:\n",
    "    y_pred: predicted labels\n",
    "    y: test labels\n",
    "    '''\n",
    "    return sum([i == j for (i, j) in zip(y_pred, y)])/len(y)\n",
    "\n",
    "def calculate_primal(y, X, w, lambda_):\n",
    "    '''\n",
    "    Computes the primal loss with the regularizer term lambda\n",
    "    '''\n",
    "    v = hinge_loss(y, X, w)\n",
    "    return sum(v) + lambda_ / 2 * sum([w_i**2 for w_i in w])\n",
    "\n",
    "def set_labels(cat, id_, id_to_labels):\n",
    "    '''\n",
    "    Converts the article ids to a label vector for SVM given a category 'cat'\n",
    "    '''\n",
    "    labels = [1 if cat in id_to_labels[x] else -1 for x in id_]\n",
    "    return labels\n",
    "\n",
    "def split_data(tx, ty, ratio, seed=1):\n",
    "    '''\n",
    "    Splits the training data by ratio (dedicated to training)\n",
    "    '''\n",
    "    split_idxs = [i for i in range(len(tx))]\n",
    "    \n",
    "    # Shuffle the indices randomly\n",
    "    shuffle(split_idxs)\n",
    "    \n",
    "    tx_shuffled = []\n",
    "    ty_shuffled = []\n",
    "    for i in range(len(split_idxs)):\n",
    "        tx_shuffled.append(tx[split_idxs[i]])\n",
    "        ty_shuffled.append(ty[split_idxs[i]])\n",
    "    \n",
    "    # Split by ratio\n",
    "    split_pos = int(len(tx) * ratio)\n",
    "    x_train = tx_shuffled[:split_pos]\n",
    "    x_test = tx_shuffled[split_pos:]\n",
    "    y_train = ty_shuffled[:split_pos]\n",
    "    y_test = ty_shuffled[split_pos:]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def inbalance(labels):\n",
    "    '''\n",
    "    Computes the proportions of the 1s and (-1)s to balance penalizer terms\n",
    "    when calculating the loss\n",
    "    '''\n",
    "    size = len(labels)\n",
    "    c = Counter(labels)\n",
    "    corr_1 = (0.5*size)/c[-1]\n",
    "    corr_2= (0.5*size)/c[1]\n",
    "    return (corr_1, corr_2)\n",
    "\n",
    "def test(input_, q,j):\n",
    "    res = stub1.ComputeTask(input_)\n",
    "    q.put(dict(res.grad_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading of the files \n",
    "file1 = open(\"../lyrl2004_vectors_test_pt0.dat\")\n",
    "file2 = open(\"../lyrl2004_vectors_test_pt1.dat\")\n",
    "file3 = open(\"../lyrl2004_vectors_test_pt2.dat\")\n",
    "file4 = open(\"../lyrl2004_vectors_test_pt3.dat\")\n",
    "files = [file1, file2, file3, file4]\n",
    "\n",
    "# Parsing the files and storing the ids of the articles along with their respective features\n",
    "id_ = []\n",
    "samples = []\n",
    "for f in files:\n",
    "    for i in f.readlines():\n",
    "        id_.append(i.split()[0])\n",
    "        samples.append(i.strip().split()[2:])\n",
    "categories = open(\"../rcv1-v2.topics.qrels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mapping of each article id to the set of categories it belongs to\n",
    "cat = []\n",
    "cat_count = {}\n",
    "id_to_labels = {}\n",
    "for line in open(\"../rcv1-v2.topics.qrels\").readlines():\n",
    "    s = line.split(' ')\n",
    "    id_to_labels.setdefault(s[1],[]).append(s[0])\n",
    "    cat_count.setdefault(s[0],[]).append(s[1])\n",
    "    cat.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the label vector based on the chosen category\n",
    "# Set the features matrix as sparse matrix by storing only the non zero components in a dict \n",
    "y = set_labels(\"C31\", id_, id_to_labels)\n",
    "X = []\n",
    "for sample in samples:\n",
    "    d = dict()\n",
    "    for feature in sample:\n",
    "        key = int(feature.split(':')[0])\n",
    "        value = float(feature.split(':')[1])\n",
    "        d[key] = value\n",
    "    X.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CCAT', 48.80891886875772),\n",
       " ('GCAT', 30.625587988710617),\n",
       " ('MCAT', 26.216456644032434),\n",
       " ('C15', 19.428106980345976),\n",
       " ('ECAT', 15.349465290266426),\n",
       " ('M14', 10.936110026687487),\n",
       " ('C151', 10.481718750999981),\n",
       " ('C152', 9.355596372549648),\n",
       " ('GPOL', 7.2802442193109895),\n",
       " ('M13', 6.865020191612321),\n",
       " ('C18', 6.7604461994329705),\n",
       " ('M11', 6.2329683270081215),\n",
       " ('M141', 6.106506755070303),\n",
       " ('C181', 5.551765406104202),\n",
       " ('E21', 5.5205340057470895),\n",
       " ('C17', 5.395736401861084),\n",
       " ('C31', 5.185052446993018),\n",
       " ('GDIP', 4.830499254414315),\n",
       " ('C13', 4.788388062949191),\n",
       " ('GSPO', 4.520489206607233),\n",
       " ('GVIO', 4.174639846914939),\n",
       " ('GCRIM', 4.123952820105854),\n",
       " ('C24', 4.11550498230434),\n",
       " ('M131', 3.6076107338739094),\n",
       " ('E212', 3.507772650765105),\n",
       " ('E12', 3.468733400318714),\n",
       " ('M132', 3.424190255547094),\n",
       " ('M12', 3.332544015154909),\n",
       " ('C21', 3.251521570785841),\n",
       " ('C11', 3.1135402200277755),\n",
       " ('C1511', 2.9709509577416116),\n",
       " ('M143', 2.8104420395128415),\n",
       " ('E51', 2.723787703276097),\n",
       " ('G15', 2.6459651974682084),\n",
       " ('C171', 2.344018994835299),\n",
       " ('GJOB', 2.2068056293319165),\n",
       " ('E41', 2.1804381355877966),\n",
       " ('E211', 2.0182652493072135),\n",
       " ('C33', 1.9624583208002409),\n",
       " ('E512', 1.6171209512777354),\n",
       " ('M142', 1.552610189884354),\n",
       " ('C12', 1.5288026469891778),\n",
       " ('C42', 1.5203548091876635),\n",
       " ('GVOTE', 1.4760676595009374),\n",
       " ('C172', 1.4703077700908143),\n",
       " ('C41', 1.4534120944877857),\n",
       " ('C411', 1.3147907560174845),\n",
       " ('GDEF', 1.13175427031801),\n",
       " ('GDIS', 1.1080747249652807),\n",
       " ('E11', 1.0966829436874812),\n",
       " ('G154', 1.0756913467261429),\n",
       " ('C14', 0.948461789533641),\n",
       " ('C183', 0.9479497993638522),\n",
       " ('C312', 0.8509276621888859),\n",
       " ('E13', 0.8451677727787626),\n",
       " ('GENV', 0.8013926132618254),\n",
       " ('C22', 0.7832169622343251),\n",
       " ('GHEA', 0.7718251809565256),\n",
       " ('C174', 0.7514735717074232),\n",
       " ('E131', 0.72433809270862),\n",
       " ('GPRO', 0.7037304883746232),\n",
       " ('E71', 0.6742910536117707),\n",
       " ('C34', 0.6188681177321396),\n",
       " ('C182', 0.5978765207708012),\n",
       " ('G158', 0.5503894325228955),\n",
       " ('C311', 0.5502614349804483),\n",
       " ('GWEA', 0.4963744696101835),\n",
       " ('GENT', 0.4865186588417503),\n",
       " ('G151', 0.4232878728728408),\n",
       " ('E511', 0.37541679199759365),\n",
       " ('GREL', 0.3646649984320301),\n",
       " ('GODD', 0.35864911393701243),\n",
       " ('C173', 0.3374015218907797),\n",
       " ('C23', 0.3359935489238607),\n",
       " ('E31', 0.3091140650099518),\n",
       " ('GSCI', 0.30847407729771587),\n",
       " ('G153', 0.30207420017535663),\n",
       " ('E513', 0.2931143722040537),\n",
       " ('E121', 0.2792906376197577),\n",
       " ('E14', 0.27865064990752175),\n",
       " ('E411', 0.2734027506671872),\n",
       " ('G155', 0.27186678015782095),\n",
       " ('G152', 0.2696908219362188),\n",
       " ('C32', 0.26674687845993356),\n",
       " ('G157', 0.2606029964224687),\n",
       " ('C16', 0.24575528149859524),\n",
       " ('GWELF', 0.23922740683378882),\n",
       " ('E311', 0.2177238197026617),\n",
       " ('C331', 0.15487702636109388),\n",
       " ('E143', 0.15436503619130512),\n",
       " ('C313', 0.1427172598286113),\n",
       " ('E132', 0.12018969235790672),\n",
       " ('GOBIT', 0.10802992582542416),\n",
       " ('GTOUR', 0.08703832886408581),\n",
       " ('E61', 0.05004703909684934),\n",
       " ('E141', 0.04812707596014156),\n",
       " ('GFAS', 0.040063230785968906),\n",
       " ('G156', 0.03327936103626811),\n",
       " ('E142', 0.025599508489437005),\n",
       " ('E313', 0.014207727211637535),\n",
       " ('E312', 0.0066558722072536216),\n",
       " ('G159', 0.0051199016978874),\n",
       " ('GMIL', 0.000639987712235925)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a ratio count of the positive examples within each class\n",
    "count = dict(cat_count)\n",
    "sum_count = sum(list(map(lambda x: len(x),count.values())))\n",
    "for k in count:\n",
    "    count[k] = (len(count[k])/len(y))*100\n",
    "\n",
    "sorted(count.items(), key=operator.itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "x_train, y_train, x_test, y_test = split_data(X, y, ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 'balancing' ratios (used to fairly penalize the negative vs positive examples)\n",
    "c1, c2 = inbalance(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5265325171814792 9.92240038101286\n"
     ]
    }
   ],
   "source": [
    "print(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random sample from the training set\n",
    "rd = randint(0,len(x_train))    \n",
    "batch = x_train[rd]\n",
    "lab = y_train[rd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up 2 channels for the communication\n",
    "channel1 = grpc.insecure_channel('localhost:50051')\n",
    "channel2 = grpc.insecure_channel('localhost:52251')\n",
    "stub1 = sgd_pb2_grpc.SGDStub(channel1)\n",
    "stub2 = sgd_pb2_grpc.SGDStub(channel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282020.86614880635\n",
      "Training accuracy = 0.8299680646131594\n",
      "Test accuracy = 0.8289952832905608\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters for the SGD\n",
    "max_iter = 1000\n",
    "worker = 10\n",
    "q = queue.Queue()\n",
    "weights = zeros(47237)\n",
    "l_rate = 0.3\n",
    "\n",
    "# Performs the SVM using SGD\n",
    "for i in range(max_iter):\n",
    "    results = []\n",
    "    threads = []\n",
    "    for j in range(worker):\n",
    "        rd = randint(0,len(x_train))\n",
    "        batch = x_train[rd]\n",
    "        lab = y_train[rd]\n",
    "        args_ = (sgd_pb2.LWB(labels=lab, weights=weights, batch=batch, corr_1=c1, corr_2=c2),q,j)\n",
    "        t = th.Thread(target=test, args=args_)\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    for j in range(worker):\n",
    "        threads[j].join()\n",
    "    \n",
    "    while not q.empty():\n",
    "        results.append(q.get())\n",
    "    for update in results:\n",
    "        for x in update:\n",
    "            weights[x] -= l_rate * update[x]\n",
    "    #print(calculate_primal(labels,X,weights,0.01))\n",
    "print(calculate_primal(y_train, x_train, weights,0.01))\n",
    "print('Training accuracy = {}'.format(accuracy(prediction(x_train, weights), y_train)))\n",
    "print('Test accuracy = {}'.format(accuracy(prediction(x_test, weights), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f1_score(labels,prediction(X, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = precision_score(labels,prediction(X, weights))\n",
    "r = recall_score(labels,prediction(X, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.740962516982 0.643446356275 0.873316104438\n"
     ]
    }
   ],
   "source": [
    "print(f,p,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "1. Transform the weight vector from a list to a dict that contains only the non zero features(same as X)\n",
    "2. After each addition/substraction/multiplication, check for the zero equality for each element, in which case the zero components need to be ommited.\n",
    "3. *accuracy* needs to be checked, something is wrong when computing the accuracy, takes way too much time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
